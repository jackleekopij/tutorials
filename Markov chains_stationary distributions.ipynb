{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains - Stationary distribution\n",
    "\n",
    "**Question** \n",
    "<Insert\n",
    "\n",
    "To calculate the long-term average cost is a two-step process. First calculate the steady distribution of states then subsequently calculate the expected value (average) pay off for the company by multiplying probabilities by *income*.\n",
    "\n",
    "The notebook is broken into three sections: \n",
    "1. Introduction to Markov chains\n",
    "2. Solution 1: Brute force\n",
    "3. Solution 2: Eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "### What is a Markov Chain\n",
    "Markov chain stochastic process which models the evolution of a random process through time. At each time step the process transitions between states, in the case relating to the question above the state space is {Sunny, Cloudy, Stormy}. Every step of a Markov chain evolves, probabilistically, in accordance to a **transition matrix**. A **transition matrix** is a map which defines conditional probability distribution over states for the transition from a state at time, t, to a set of states at time t + 1. Constraints on this matrix require that:\n",
    "    1. elements of row sum to 1\n",
    "    2. all elements > 0\n",
    "\n",
    "From the question, the Markov chain has the following transition matrix:\n",
    "\n",
    "$$ \\pi = \n",
    "\\begin{bmatrix}\n",
    "    0.8 & 0.2 &  0   \\\\\n",
    "    0.1 & 0.8 &  0.1 \\\\\n",
    "    0   & 0.2 &  0.8\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "**Initial state distribution** \n",
    "\n",
    "**Assumption of constant time**\n",
    "\n",
    "**Markov equality**\n",
    "\n",
    "\n",
    "\n",
    "In our example the process is concerned has both a discrete state space and time measures. Other classes of Markov proce\n",
    "Come in discrete and continuous time and state versions. Here we  \n",
    "Evolution of probabilities through \n",
    "\n",
    "A transition probability matrix - \n",
    "    gives probability of transitioning from one state to another\n",
    "    usual probability constraints apply -> rows must sum to one and elements must be greater than zero.\n",
    "\n",
    "\n",
    "### Marginal distributions - the law of total probability \n",
    "Of interest is how a Markov chain evolves through time. Thus calculating the probability of a the process being a given state at any point in time is central to the study of Markov chains. This probability is also referred to as a *marginal distribution*. Computing the *marginal distribution* requires only simple matrix multiplication and knowledge of both the *initial state* and *transition distribution*. In other terms the probability distribution across states of a Markov chain can be computed at **any** point in time with knowledge of just the *initial state* and *transition distribution*. \n",
    "\n",
    "To see why the *marginal distribution* can be obtained let's turn to use *transition matrix* from the question. Further let's assume a uniform for the *initial distribution*, again assigns an equal probability to starting in each state. For the example provided, we have \n",
    "\n",
    "$$  \\textbf{P}_0  = [\\frac{1}{3}, \\frac{1}{3} ,\\frac{1}{3} ] $$\n",
    "\n",
    "Note: the subbed zero is indicates that this is an *initial distribution*, i.e. the distribution of the process at time = 0.\n",
    "\n",
    "A natural question, what is the probability distribution at time step, t = 1? In more specific terminology, what is the *marginal distribution* at time t = 1 which is written as $P(X_1)$ ? To calculate the marginal distribution the law of total probability is used, given as: \n",
    "\n",
    "$$ P(X_1 = j) = \\sum^{N}_{i = 1}P(X_1 = j| X_0 = i) P(X_0 = i) $$\n",
    "\n",
    "The *law of total probability* can be used as follows to calculate $P(X_1 = \\text{Sunny} )$. Below the *transition matrix* and the *initial distribution* have been used$: \n",
    "\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "&\\\\\n",
    "P(X_1 = \\text{Sunny}) \n",
    "    &= P(X_1 = \\text{Sunny}| X_0 = \\text{Sunny}) P(X_0 = \\text{Sunny}) \n",
    "    \\\\ & + P(X_1 = \\text{Sunny}| X_0 = \\text{Cloudy}) P(X_0 = \\text{Cloudy}) \n",
    "    \\\\ & + P(X_1 = \\text{Sunny}| X_0 = \\text{Stormy}) P(X_0 = \\text{Stormy})\n",
    "    \\\\ & = 0.8 * \\frac{1}{3} + 0.1 * \\frac{1}{3} + 0 * \\frac{1}{3} \n",
    "    \\\\ & = 0.3\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "**As an excercise calculate $P(X_1 = \\text{Cloudy} )$ and $P(X_1 = \\text{Stormy} )$**\n",
    "\n",
    "Above the calculations have been done in an elementwise approach. However, this can be simplified to the following matrix multiplication where $P_{x,y}$ is the transition probability from state x at time t to state y at time t + 1: \n",
    "\n",
    "\\begin{equation*}\n",
    "    P_1 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}] \n",
    "    =  P_0 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}]\n",
    "    \\begin{bmatrix}\n",
    "        P_{Sunny,Sunny}  & P_{Sunny,Cloudy}   &  P_{Sunny,Stormy}    \\\\\n",
    "        P_{Cloudy,Sunny} & P_{Cloudy,Cloudy}  &  P_{Cloudy,Stormy}   \\\\\n",
    "        P_{Stormy,Sunny} & P_{Stormy,Cloudy}  &  P_{Stormy,Stormy}   \\\\\n",
    "    \\end{bmatrix} \n",
    "\\end{equation*}\n",
    "\n",
    "In a compact form this is written as: \n",
    "\n",
    "\\begin{equation*}\n",
    "    P_{t+1} = P_{t} \\pi\n",
    "\\end{equation*}\n",
    "\n",
    "Where $P_t$ is the marginal distribution at time t and $\\pi$ is the transition matrix.\n",
    "\n",
    "### Stationary distributions (steady states)\n",
    "With the overview of Markov chains and marginal distributions, the final piece to solving the question is the *steady state distribution*. The *steady state distribution* is an **assumption**, that as the process evolves for an infinite amount of time the *marginal distributions* at each time step will to a unique distribution. In such a scenario the following equation would arise: \n",
    "\n",
    "$$\n",
    "    P = P \\pi \n",
    "$$\n",
    "\n",
    "With all the required pieces in place two solutions are provided:\n",
    "1. A numerical (brute) force approach\n",
    "2. An analytical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solution 1: Brute force\n",
    "One approach to solving for the stationary distribution is to simply caclute the *marginal distribution* at a very large time. The inductive reasoning behind this; at each time step the *marginal distribution* is the *transition matrix* multiplied by the previous time step's *marginal distribution*. \n",
    "\n",
    "At **t = 1**, \n",
    "\\begin{equation*}\n",
    "    P_1 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}] \n",
    "    =  P_0 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}]\n",
    "    \\begin{bmatrix}\n",
    "        P_{Sunny,Sunny}  & P_{Sunny,Cloudy}   &  P_{Sunny,Stormy}    \\\\\n",
    "        P_{Cloudy,Sunny} & P_{Cloudy,Cloudy}  &  P_{Cloudy,Stormy}   \\\\\n",
    "        P_{Stormy,Sunny} & P_{Stormy,Cloudy}  &  P_{Stormy,Stormy}   \\\\\n",
    "    \\end{bmatrix} \n",
    "\\end{equation*}\n",
    "\n",
    "At **t = 2**, \n",
    "\\begin{equation*}\n",
    "    P_2 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}] \n",
    "    =  P_1 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}]\n",
    "    \\begin{bmatrix}\n",
    "        P_{Sunny,Sunny}  & P_{Sunny,Cloudy}   &  P_{Sunny,Stormy}    \\\\\n",
    "        P_{Cloudy,Sunny} & P_{Cloudy,Cloudy}  &  P_{Cloudy,Stormy}   \\\\\n",
    "        P_{Stormy,Sunny} & P_{Stormy,Cloudy}  &  P_{Stormy,Stormy}   \\\\\n",
    "    \\end{bmatrix} \n",
    "\\end{equation*}\n",
    "\n",
    "now $P_1 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}]$ can be substituted to yield: \n",
    "\\begin{equation*}\n",
    "    P_2 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}]  \n",
    "    =  P_0 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}] \n",
    "    \\begin{bmatrix}\n",
    "        P_{Sunny,Sunny}  & P_{Sunny,Cloudy}   &  P_{Sunny,Stormy}    \\\\\n",
    "        P_{Cloudy,Sunny} & P_{Cloudy,Cloudy}  &  P_{Cloudy,Stormy}   \\\\\n",
    "        P_{Stormy,Sunny} & P_{Stormy,Cloudy}  &  P_{Stormy,Stormy}   \\\\\n",
    "    \\end{bmatrix}^{\\textbf{ 2} }\n",
    "\\end{equation*}\n",
    "\n",
    "This logic can then be extended to solve for the nth step *marginal distribution* by the following: \n",
    "\\begin{equation*}\n",
    "    P_n [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}]  \n",
    "    =  P_0 [\\text{Sunny}, \\text{Cloudy}, \\text{Stormy}] \n",
    "    \\begin{bmatrix}\n",
    "        P_{Sunny,Sunny}  & P_{Sunny,Cloudy}   &  P_{Sunny,Stormy}    \\\\\n",
    "        P_{Cloudy,Sunny} & P_{Cloudy,Cloudy}  &  P_{Cloudy,Stormy}   \\\\\n",
    "        P_{Stormy,Sunny} & P_{Stormy,Cloudy}  &  P_{Stormy,Stormy}   \\\\\n",
    "    \\end{bmatrix}^{\\textbf{ n} }\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "By nature of the stationary distribution, once n becomes sufficiently large the transition matrix raised to this power becomes appoaches the stationary distribution of the Markov chain. In the example below, it is shown that as small as 100 iterations is enough for the *marginal distribution* to converge. Of note, the choice of *initial distribution*, $P_0(X)$ does not impact the calculation of the *stationary distribution*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution at time step 100: [0.25 0.5  0.25]\n",
      "Distribution at time step 101: [0.25 0.5  0.25]\n"
     ]
    }
   ],
   "source": [
    "# Brute force calculation in Python\n",
    "import numpy as np\n",
    "from numpy.linalg import matrix_power\n",
    "\n",
    "\n",
    "initial_distribution = np.array([0.333, 0.333, 0.334])\n",
    "transition_matrix = np.array([[0.8,  0.2, 0 ],\n",
    "                              [0.1,  0.8, 0.1],\n",
    "                              [0  ,  0.2, 0.8]])\n",
    "\n",
    "# raise transition matrix to power 100\n",
    "stationary_distribution = initial_distribution.dot( matrix_power(transition_matrix, 100))\n",
    "print(\"Distribution at time step 100: {}\".format(stationary_distribution))\n",
    "\n",
    "# raise transition matrix to power 101\n",
    "stationary_distribution = initial_distribution.dot( matrix_power(transition_matrix, 101))\n",
    "print(\"Distribution at time step 101: {}\".format(stationary_distribution))\n",
    "\n",
    "\n",
    "# Note both of these distributions have converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Solution 2: Eigenvectors\n",
    "P"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
